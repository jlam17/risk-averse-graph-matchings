from collections import defaultdict
import numpy as np
import time

MAX_MATCHING = float('inf')
np.seterr(divide='raise', invalid='raise')

class Hypergraph:
    edge = 'edge'
    weight = 'weight'
    probability = 'probability'
    expected_weight = 'expected_weight'
    variance = 'variance'
    standard_deviation = 'standard_deviation'
    alpha = 'alpha'
    beta = 'beta'
    edge_distribution = 'bernoulli'
    edge_count = 'edges'
    runtime = 'runtime'
    epsilon = 0.01
    variance_beta = False
    adj_list, alpha_sorted, exp_weight_sorted = None, None, None

    def __setattr__(self, name, value):
        # Only allowed pre-defined attributes above to be set
        if hasattr(self, name):
            super(Hypergraph, self).__setattr__(name, value)
        else:
            raise KeyError('Passed a bad key argument {}'.format(name))

    def __repr__(self):
        if self.edge_distribution == 'bernoulli':
            edges = len(self.alpha_sorted)
            avg_p1 = np.mean([e[self.weight] for e in self.alpha_sorted])
            avg_p2 = np.mean([e[self.probability] for e in self.alpha_sorted])
            return '{} edges in (hyper)graph w/ {} avg weight {} avg probability'.format(edges, avg_p1, avg_p2)
        elif self.edge_distribution == 'gaussian':
            edges = len(self.alpha_sorted)
            avg_p1 = np.mean([e[self.expected_weight] for e in self.alpha_sorted])
            avg_p2 = np.mean([e[self.variance] for e in self.alpha_sorted])
            return '{} edges in (hyper)graph w/ {} avg weight {} avg probability'.format(edges, avg_p1, avg_p2)
        else:
            return 'Hypergraph has not been defined'

    # TODO: make default weight 1, default prob 1 standard unweighted certain graph
    def __init__(self, edge_list, variance_beta=False, **kwargs):
        """
        Initializes a (hyper)graph for finding bounded-variance matchings

        :param edge_list list: list of dicts defining edges in a (hyper)graph
        :param variance_beta bool: standard deviation (False) or variance (True) beta thresholds
        :param \**kwargs: keyword arguments specifying keys for accessing values in 'edge_list'
        :raises KeyError: specified incorrect key in **kwargs
        :raises ValueError: bad edge values
        """
        # variance or standard dev risk-averse matching
        self.variance_beta = variance_beta

        # change default edge attributes
        for key, value in kwargs.items():
            setattr(self, key, value)

        # Generate expected weight, variance, standard deviation, and alpha
        data = self.__init_attributes(edge_list)

        # data structures for finding matchings
        self.adj_list = defaultdict(lambda: defaultdict(int))
        self.alpha_sorted = sorted(data, key=lambda d: (d[self.alpha], -d[self.probability]), reverse=True)
        self.exp_weight_sorted = sorted(data, key=lambda d: d[self.expected_weight], reverse=True)

    def __init_attributes(self, edges):
        '''
        Generate following edge attributes based on distribution of edge: expected weight,
        variance, standard deviation, and alpha. Alpha values generated based
        on based on standard deviation or variance

        Gaussian distributed edges should have mean and variance defined.
        Bernoulli distributed edges should have weight and probability defined.

        :param edges list: list of dicts defining edges in a (hyper)graph
        :return: list of dicts w/ additional generated values
        '''
        try:
            distrib = self.edge_distribution
            if distrib == 'gaussian':
                for entry in edges:
                    entry[self.weight], entry[self.probability] = 0, 0
                    if entry[self.variance] != 0:
                        if entry[self.variance] < 0 or entry[self.expected_weight] < 0:
                            raise FloatingPointError('Invalid negative value in edge {}'.format(entry))

                        beta = entry[self.variance] if self.variance_beta else np.sqrt(entry[self.variance])
                        entry[self.alpha] = entry[self.expected_weight] / beta
                        entry[self.standard_deviation] = self.calc_standard_dev([entry], distrib)
                    else:
                        # we slightly perturb zero variance edges. alternatively these edges are
                        # included in all sub-hypergraphs generated by the algorithm, as they never hurt.
                        entry[self.alpha] = float("inf")
                        entry[self.standard_deviation] = 0
            elif distrib == 'bernoulli':
                for entry in edges:
                    # we slightly perturb zero weight edges and zero/one probability edges.
                    w = self.epsilon if entry[self.weight] == 0 else entry[self.weight]
                    p = self.epsilon if entry[self.probability] == 0 \
                        else 1 - self.epsilon if entry[self.probability] == 1 \
                        else entry[self.probability]
                    if w < 0 or p < 0:
                        raise FloatingPointError('Invalid negative value in edge {}'.format(entry))

                    beta = (w**2 * (p * (1 - p))) if self.variance_beta else w * np.sqrt(p * (1 - p))
                    entry[self.alpha] = w * p / beta
                    entry[self.expected_weight] = entry[self.probability] * entry[self.weight]
                    entry[self.standard_deviation] = self.calc_standard_dev([entry], distrib)
                    entry[self.variance] = self.calc_variance([entry], distrib)
            else:
                raise ValueError('Only bernoulli and gaussian distributed edges supported')
        except KeyError as e:
            raise KeyError('Did not define attribute "{}" in **kwargs'.format(e.args[0]))

        return edges

    def print_stats(self, stats, threshold=None):
        stats['probability'] = stats['probability']/stats['edges'] if stats['edges'] > 0 else 0
        print(''.join(['{1:.2f} {0}, '.format(k, v) for k,v in sorted(stats.items(), key=lambda x: x[0])]))

    def __add_adj_list(self, edges=None):
        '''
        Update adjacency list with specified additional edges (larger subgraph).
        If edges not specified, update adjacency list with all edges (entire graph)

        :param edges list: list of edges to update adjacency list with
        '''
        if edges is None:
            if len(self.adj_list) > 0:
                raise ValueError('Please delete all edges from adjacency list before adding all edges')
            edges = self.exp_weight_sorted

        for edge in edges:
            for author in edge[self.edge]:
                self.adj_list[author]['nodes'] += 1
                self.adj_list[author]['matched'] = False

    def __del_adj_list(self, edges=None):
        '''
        Update adjcancy list by removing specified edges (smaller subgraph)
        If edges not specified, remove all edges from adjacency list

        :param edges list : list of edges to remove from adjacency list
        '''
        if edges is None:
            self.adj_list = defaultdict(lambda: defaultdict(int))
            return
        for edge in edges:
            for author in edge[self.edge]:
                self.adj_list[author]['nodes'] -= 1
                if self.adj_list[author]['nodes'] == 0 :
                    self.adj_list.pop(author)

    def gen_betas(self, intervals):
        '''
        Generate evenly spaced intervals based on the standard deviation

        :param intervals int: number of evenly spaced intervals
        :return: list of (beta) threshold values
        '''
        threshold_vals = None
        _, stats = self.max_matching()
        maxi = int(np.ceil(stats[self.variance])) if self.variance_beta else np.ceil(stats[self.standard_deviation])
        mini = 0
        threshold_vals = [round(val) for val in np.linspace(mini, maxi,intervals+1)]
        print('Generating beta thresholds (variance type {}): {}'.format(self.variance_beta, threshold_vals))
        return threshold_vals

    def __greedy_matching(self, min_alpha, total_edges=None, threshold=None):
        '''
        Find a maximal matching for a given specified subgraph (min alpha of subgraph)

        Algorithm
        ---------
        For all edges in 'self.exp_weight_sorted' with alpha > min_alpha
        find a maximal matching using a greedy approach that picks edges
        in the order of highest expected weight. Using 'self.adj_list' to
        keep track of whether vertices have been picked or not in matching.

        :param min_alpha float: minimum alpha value of the subgraph
        :param total_edges int: number of edges in the subgraph
        :param threshold float: max beta threshold an edge should not exceed
        :return: matching found, and matchings' statistics
        '''
        # greedy matching statistics
        matching_stats = defaultdict(int)

        matching_edges = []
        vertices_removed = []
        e_attribs = [self.weight, self.probability, self.expected_weight, self.variance, self.standard_deviation]
        count = 0
        for e in self.exp_weight_sorted:
            # skip edges with alpha < min alpha of current subgraph
            if min_alpha != MAX_MATCHING and e[self.alpha] <= min_alpha:
                continue

            # breaks when all valid edges in subgraph have been considered
            # TODO: possible bug here
            if total_edges and count == total_edges:
                break
            count += 1

            # skip edge if its standard dev/variance is greater than the current threshold
            #TODO: possible bug for not picking up edges with std = 0 and threshold = 0
            beta = e[self.variance] if self.variance_beta else e[self.standard_deviation]
            if threshold and beta > threshold:
                if total_edges < 10:
                    print(beta, threshold)
                continue
            # check if valid edge ie. all authors for hyperedge are still available
            available = True
            for author in e[self.edge]:
                if self.adj_list[author]['matched']:
                    available = False
                    break
            if available:
                for e_attrib in e_attribs:
                    matching_stats[e_attrib] += e[e_attrib]
                matching_edges.append(e)
                # flag vertices that should not be considered
                for author in e[self.edge]:
                    self.adj_list[author]['matched'] = True
                    vertices_removed.append(author)
        # reset adjacency list
        for author in vertices_removed:
            self.adj_list[author]['matched'] = False

        matching_stats[self.edge_count] = len(matching_edges)
        return matching_edges, matching_stats

    def bounded_matching(self, threshold):
        '''
        Find a greedy matching on a subgraph s.t. greedy matching's total beta
        (variance or standard dev beta specified in initialization) < specified
        'threshold'. Uses binary search to find this subgraph.

        Outputs the maximum expected weight of the greedy matching found and
        the next edge that was not considered in the greedy matching.

        :param threshold float: max beta of greedy matching
        :return: matching found, matchings' statistics
        '''
        start = time.time()
        hi = len(self.alpha_sorted) - 1
        lo = 0
        mid = (hi + lo)//2
        self.__del_adj_list()
        self.__add_adj_list(self.alpha_sorted[:mid])

        while True:
            min_alpha = self.alpha_sorted[mid][self.alpha]
            matching, stats = self.__greedy_matching(min_alpha, total_edges=mid, threshold=threshold)
            matching_beta = stats[self.variance] if self.variance_beta else stats[self.standard_deviation]

            if hi <= mid or lo >= mid:
                break
            elif threshold - matching_beta < 0.1 and threshold - matching_beta > 0:
                break
            elif matching_beta < threshold:
                lo = mid
                mid = (hi+lo)//2
                self.__add_adj_list(self.alpha_sorted[lo:mid])
            else:
                hi = mid
                mid = (hi+lo)//2
                self.__del_adj_list(self.alpha_sorted[mid:hi])
        total_time = time.time() - start
        stats = self.gen_stats(stats, total_time, threshold)

        #TODO: messy implementation, fix it
        # Max of greedy matching and next edge that was not considered in greedy matching
        e_next = self.alpha_sorted[mid]
        e_attribs = [self.weight, self.probability, self.expected_weight, self.variance, self.standard_deviation]
        e_next_stats = defaultdict(int)
        for e_attrib in e_attribs:
            e_next_stats[e_attrib] += e_next[e_attrib]
        e_next_stats = self.gen_stats(e_next_stats, 0, threshold)
        e_next_stats[self.edge_count] = 1
        return max((matching, stats), ([e_next], e_next_stats), key=lambda x: x[1][self.expected_weight])

    def max_matching(self):
        '''
        Find a greedy matching on the entire graph

        :return: matching found, matchings' statsitics
        '''
        # initialize variables
        self.__del_adj_list()
        self.__add_adj_list()

        start = time.time()
        matching, stats = self.__greedy_matching(MAX_MATCHING)
        total_time = time.time() - start
        stats = self.gen_stats(stats, total_time)

        return matching, stats

    def gen_stats(self, stats, total_time, threshold=None):
        '''
        Add a runtime and threshold to stats of the greedy matching found
        '''
        stats[self.runtime] = total_time
        if threshold is not None:
            stats[self.beta] = threshold
            stats['variance_beta'] = self.variance_beta
        return stats

    def calc_standard_dev(self, edges, distrib):
        if distrib == 'gaussian':
            return sum(np.sqrt(e[self.variance]) for e in edges) # sqrt(variance)
        elif distrib == 'bernoulli':
            return sum(e[self.weight] * np.sqrt(e[self.probability] * (1-e[self.probability])) for e in edges) # w(sqrt(p(1-p)))
        else:
            raise ValueError("Only gaussian and bernoulli are supported")

    def calc_variance(self, edges, distrib):
        if distrib == 'gaussian':
            return sum(e[self.variance] for e in edges) # variance
        elif distrib == 'bernoulli':
            return sum(e[self.weight]**2 * e[self.probability] * (1-e[self.probability]) for e in edges) # w^2(p(1-p))
        else:
            raise ValueError("Only gaussian and bernoulli are supported")


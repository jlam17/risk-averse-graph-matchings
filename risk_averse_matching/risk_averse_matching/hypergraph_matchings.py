from collections import defaultdict
import numpy as np
import time

MAX_MATCHING = float('inf')

class Hypergraph:
    edge = 'edge'
    weight = 'weight'
    probability = 'probability'
    expected_weight = 'expected_weight'
    variance = 'variance'
    standard_deivation = 'standard_deviation'
    alpha = 'alpha'
    beta = 'beta'
    edge_distribution = 'bernoulli'
    edge_count = 'edges'
    runtime = 'runtime'
    epsilon = 0.01
    variance_beta = False

    def __setattr__(self, name, value):
        # Only allowed pre-defined attributes above to be set
        if hasattr(self, name):
            super(Hypergraph, self).__setattr__(name, value)
        else:
            raise KeyError('Passed a bad key argument')

    def __repr__(self):
        if self.edge_distribution == 'bernoulli':
            edges = len(self.alpha_sorted)
            avg_p1 = np.mean([e[self.weight] for e in self.alpha_sorted])
            avg_p2 = np.mean([e[self.probability] for e in self.alpha_sorted])
            return '{} edges in (hyper)graph w/ {} avg weight {} avg probability'.format(edges, avg_p1, avg_p2)
        elif self.edge_distribution == 'gaussian':
            edges = len(self.alpha_sorted)
            avg_p1 = np.mean([e[self.expected_weight] for e in self.alpha_sorted])
            avg_p2 = np.mean([e[self.variance] for e in self.alpha_sorted])
            return '{} edges in (hyper)graph w/ {} avg weight {} avg probability'.format(edges, avg_p1, avg_p2)
        else:
            return 'Hypergraph has not been defined'

    # TODO: make default weight 1, default prob 1 standard unweighted certain graph
    def __init__(self, edge_list, variance_beta=False, **kwargs):
        """
        Initializes a (hyper)graph for finding bounded-variance matchings

        :param edge_list list: list of dicts defining edges in a (hyper)graph
        :param variance_beta bool: standard deviation (False) or variance (True) beta thresholds
        :param \**kwargs: keyword arguments specifying keys for accessing values in 'edge_list'
        :raises KeyError: specified incorrect key in **kwargs
        :raises ValueError: bad edge values
        """
        # variance or standard dev risk-averse matching
        self.variance_beta = variance_beta

        # change default edge attributes
        for key, value in kwargs.items():
            setattr(self, key, value)

        # check that attributes in 'edge_list' have been defined
        for key in edge_list[0].keys():
            if not hasattr(self, key):
                raise KeyError('Did not define attribute {} in **kwargs'.format(key))

        # Generate expected weight, variance, standard deviation, and alpha
        data = self.__init_attributes(edge_list, self.edge_distribution, variance_beta)

        # data structures for finding matchings
        self.adj_list = defaultdict(lambda: defaultdict(int))
        self.alpha_sorted = sorted(data, key=lambda d: (d[self.alpha], -d[self.probability]), reverse=True)
        self.exp_weight_sorted = sorted(data, key=lambda d: d[self.expected_weight], reverse=True)

    def __init_attributes(self, edges, distrib):
        '''
        Generate following edge attributes based on distribution of edge: expected weight,
        variance, standard deviation, and alpha. Alpha values generated based
        on based on standard deviation or variance

        Gaussian distributed edges should have mean and variance defined.
        Bernoulli distributed edges should have weight and probability defined.

        :param edges list: list of dicts defining edges in a (hyper)graph
        :param distrib str: distribution of edges ('bernoulli' or 'gaussian')
        :return: list of dicts w/ additional generated values
        '''

        if distrib == 'gaussian':
            for entry in edges:
                entry[self.weight], entry[self.probability] = 0, 0
                if entry[self.variance] != 0:
                    beta = entry[self.variance] if self.variance_beta else np.sqrt(entry[self.variance])
                    entry[self.alpha] = entry[self.expected_weight] / beta
                    entry[self.standard_deviation] = self.calc_standard_dev([entry], distrib)
                else:
                    # we slightly perturb zero variance edges. alternatively these edges are
                    # included in all sub-hypergraphs generated by the algorithm, as they never hurt.
                    entry[self.alpha] = float("inf")
                    entry[self.standard_deviation] = 0
        elif distrib == 'bernoulli':
            for entry in edges:
                # we slightly perturb zero weight edges and zero or one probability edges.
                w = self.epsilon if entry[self.weight] == 0 else entry[self.weight]
                p = self.epsilon if entry[self.probability] == 0 \
                    else 1 - self.epsilon if entry[self.probability] == 1 \
                    else entry[self.probability]

                beta = (w**2 * (p * (1 - p))) if self.variance_beta else w * np.sqrt(p * (1 - p))
                entry[self.alpha] = w * p / beta
                entry[self.expected_weight] = entry[self.probability] * entry[self.weight]
                entry[self.standard_deviation] = self.calc_standard_dev([entry], distrib)
                entry[self.variance] = self.calc_variance([entry], distrib)
        else:
            raise ValueError('Only bernoulli and gaussian distributed edges supported')

        return edges

    def print_stats(self, stats, threshold=None):
        stats['probability'] = stats['probability']/stats['edges'] if stats['edges'] > 0 else 0
        if threshold:
            print('{self.beta:.2f} beta threshold {self.variance_beta} variance beta: {self.edge_count} edges, {self.weight} weight, {self.probabililty:.2f} avg probability, {self.expected_weight:2f} exp_weight, {self.standard_deviation:.2f} std, {self.variance:.2f} var {self.runtime:.2f} time'.format(**stats))
        else:
            print('{self.edge_count} edges, {self.weight} weight, {self.probabililty:.2f} avg probability, {self.expected_weight:2f} exp_weight, {self.standard_deviation:.2f} std, {self.variance:.2f} var {self.runtime:.2f} time'.format(**stats))

    def __add_adj_list(self, edges=None):
        '''
        Update adjacency list with specified additional edges (larger subgraph).
        If edges not specified, update adjacency list with all edges (entire graph)

        :param edges list: list of edges to update adjacency list with
        '''
        if edges is None:
            if len(self.adj_list) > 0:
                raise ValueError('Please delete all edges from adjacency list before adding all edges')
            edges = self.exp_weight_sorted

        for edge in edges:
            for author in edge[self.edge]:
                self.adj_list[author]['nodes'] += 1
                self.adj_list[author]['matched'] = False

    def __del_adj_list(self, edges=None):
        '''
        Update adjcancy list by removing specified edges (smaller subgraph)
        If edges not specified, remove all edges from adjacency list

        :param edges list : list of edges to remove from adjacency list
        '''
        if edges is None:
            self.adj_list = defaultdict(lambda: defaultdict(int))
            return
        for edge in edges:
            for author in edge[self.edge]:
                self.adj_list[author]['nodes'] -= 1
                if self.adj_list[author]['nodes'] == 0 :
                    self.adj_list.pop(author)

    def gen_betas(self, intervals):
        '''
        Generate evenly spaced intervals based on the standard deviation

        :param intervals int: number of evenly spaced intervals
        :return: list of (beta) threshold values
        '''
        threshold_vals = None
        _, stats = self.max_matching()
        maxi = int(np.ceil(stats[self.variance])) if self.variance_beta else np.ceil(stats[self.standard_deviation])
        mini = 0
        threshold_vals = [round(val) for val in np.linspace(mini, maxi,intervals+1)]
        print('Generating beta thresholds (variance type {}): {}'.format(self.variance_beta, threshold_vals))
        return threshold_vals

    def __greedy_matching(self, min_alpha, total_edges=None, threshold=None):
        '''
        Find a maximal matching for a given specified subgraph (min alpha of subgraph)

        Algorithm
        ---------
        For all edges in 'self.exp_weight_sorted' with alpha > min_alpha
        find a maximal matching using a greedy approach that picks edges
        in the order of highest expected weight. Using 'self.adj_list' to
        keep track of whether vertices have been picked or not in matching.

        :param min_alpha float: minimum alpha value of the subgraph
        :param total_edges int: number of edges in the subgraph
        :param threshold float: max beta threshold an edge should not exceed
        :return: matching found, and matchings' statistics
        '''
        # greedy matching statistics
        matching_stats = defaultdict(int)

        matching_edges = []
        vertices_removed = []
        exclude_attrib = set([self.alpha, self.edge])
        count = 0
        for e in self.exp_weight_sorted:
            # skip edges with alpha < min alpha of current subgraph
            if min_alpha != MAX_MATCHING and e[self.alpha] <= min_alpha:
                continue

            count += 1
            # skip edge if its standard dev/variance is greater than the current threshold
            beta = e[self.variance] if self.variance_beta else e[self.standard_deviation]
            if threshold and beta > threshold:
                continue
            # check if valid edge ie. all authors for hyperedge are still available
            available = True
            for author in e[self.edge]:
                if self.adj_list[author]['matched']:
                    available = False
                    break
            if available:
                for e_attrib, val in e.items():
                    if e_attrib in exclude_attrib:
                        continue
                    matching_stats[e_attrib] = val
                matching_edges.append(e)
                # flag vertices that should not be considered
                for author in e[self.edge]:
                    self.adj_list[author]['matched'] = True
                    vertices_removed.append(author)
            # breaks when all valid edges in subgraph have been considered
            # TODO: possible bug here
            if total_edges and count == total_edges:
                break
        # reset adjacency list
        for author in vertices_removed:
            self.adj_list[author]['matched'] = False

        # TODO: delete
        # return matching_edges, len(matching_edges), total_weight, total_prob, total_exp_weight, total_std, total_var
        matching_stats[self.edge_count] = len(matching_edges)
        return matching_edges, matching_stats

    def bounded_matching(self, threshold):
        '''
        Find a greedy matching on a subgraph s.t. greedy matching's total beta
        (variance or standard dev beta specified in initialization) < specified
        'threshold'. Uses binary search to find this subgraph.

        Outputs the maximum expected weight of the greedy matching found and
        the next edge that was not considered in the greedy matching.

        :param threshold float: max beta of greedy matching
        :return: matching found, matchings' statistics
        '''
        start = time.time()
        hi = len(self.alpha_sorted) - 1
        lo = 0
        mid = (hi + lo)//2
        self.__del_adj_list()
        self.__add_adj_list(self.alpha_sorted[:mid])

        while True:
            min_alpha = self.alpha_sorted[mid][self.alpha]
            matching, stats = self.__greedy_matching(min_alpha, total_edges=mid, threshold=threshold)
            matching_beta = stats[self.variance] if self.variance_beta else stats[self.standard_deviation]

            if hi <= mid or lo >= mid:
                break
            elif threshold - matching_beta < 0.1 and threshold - matching_beta > 0:
                break
            elif matching_beta < threshold:
                lo = mid
                mid = (hi+lo)//2
                self.__add_adj_list(self.alpha_sorted[lo:mid])
            else:
                hi = mid
                mid = (hi+lo)//2
                self.__del_adj_list(self.alpha_sorted[mid:hi])
        total_time = time.time() - start
        stats = self.gen_stats(total_time, threshold)

        #TODO: messy implementation, fix it
        # Max of greedy matching and next edge that was not considered in greedy matching
        e_next = list(self.alpha_sorted[mid])
        exclude_attrib = set([self.alpha, self.edge])
        e_next_stats = dict()
        for e_attrib, val in e_next.items():
            if e_attrib in exclude_attrib:
                continue
            e_next_stats[e_attrib] = val
        e_next_stats = self.gen_stats(e_next_stats, 0, threshold)
        return max((matching, stats), ([e_next], e_next_stats), key=lambda x: x[1][self.expected_weight])

    def max_matching(self):
        '''
        Find a greedy matching on the entire graph

        :return: matching found, matchings' statsitics
        '''
        # initialize variables
        self.__del_adj_list()
        self.__add_adj_list()

        start = time.time()
        greedy_matching = self.__greedy_matching(MAX_MATCHING)
        total_time = time.time() - start
        matching, stats = self.gen_stats(greedy_matching, total_time)

        return matching, stats

    def gen_stats(self, stats, total_time, threshold=None):
        '''
        Add a runtime and threshold to stats of the greedy matching found
        '''
        stats[self.runtime] = total_time
        if threshold is not None:
            stats[self.beta] = threshold
            stats['variance_beta'] = self.variance_beta
        return stats

    def calc_standard_dev(self, edges, distrib):
        if distrib == 'gaussian':
            return sum(np.sqrt(e[self.variance]) for e in edges) # sqrt(variance)
        elif distrib == 'bernoulli':
            return sum(e[self.weight] * np.sqrt(e[self.probability] * (1-e[self.probability])) for e in edges) # w(sqrt(p(1-p)))
        else:
            raise ValueError("Only gaussian and bernoulli are supported")

    def calc_variance(self, edges, distrib):
        if distrib == 'gaussian':
            return sum(e[self.variance] for e in edges) # variance
        elif distrib == 'bernoulli':
            return sum(e[self.weight]**2 * e[self.probability] * (1-e[self.probability]) for e in edges) # w^2(p(1-p))
        else:
            raise ValueError("Only gaussian and bernoulli are supported")

